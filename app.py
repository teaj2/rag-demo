import gradio as gr
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re
import jieba  # ä¸­æ–‡åˆ†è¯

class SimpleRAG:
    def __init__(self):
        # ä½¿ç”¨TF-IDFä½œä¸ºè½»é‡çº§çš„æ–‡æœ¬å‘é‡åŒ–æ–¹æ³•
        self.vectorizer = TfidfVectorizer(
            max_features=1000,
            stop_words=None,
            ngram_range=(1, 3),  # å¢åŠ 3-gramæé«˜åŒ¹é…åº¦
            min_df=1,  # æœ€å°æ–‡æ¡£é¢‘ç‡
            lowercase=True,
            analyzer='word'
        )
        
        # çŸ¥è¯†åº“
        self.documents = []
        self.doc_vectors = None
        self.vectorizer_fitted = False
        
        # åŠ è½½é»˜è®¤çŸ¥è¯†åº“
        self.load_default_knowledge()
    
    def preprocess_text(self, text):
        """æ–‡æœ¬é¢„å¤„ç† - æ”¹è¿›ä¸­æ–‡å¤„ç†"""
        # ä¿ç•™ä¸­æ–‡å­—ç¬¦ï¼Œç§»é™¤æ ‡ç‚¹ç¬¦å·
        text = re.sub(r'[^\u4e00-\u9fa5\w\s]', ' ', text)
        # ä½¿ç”¨jiebaåˆ†è¯å¤„ç†ä¸­æ–‡
        try:
            words = jieba.lcut(text)
            return ' '.join(words).lower()
        except:
            return text.lower()
    
    def load_default_knowledge(self):
        """åŠ è½½é»˜è®¤çŸ¥è¯†åº“"""
        default_docs = [
            "å¤§è¯­è¨€æ¨¡å‹LLMæ˜¯åŸºäºTransformeræ¶æ„çš„æ·±åº¦å­¦ä¹ æ¨¡å‹èƒ½å¤Ÿç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€",
            "RAGæ£€ç´¢å¢å¼ºç”Ÿæˆæ˜¯ä¸€ç§ç»“åˆæ£€ç´¢å’Œç”Ÿæˆçš„æ–¹æ³•é€šè¿‡æ£€ç´¢ç›¸å…³æ–‡æ¡£æ¥å¢å¼ºç”Ÿæˆè´¨é‡",
            "Transformeræ˜¯ä¸€ç§åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„ç¥ç»ç½‘ç»œæ¶æ„ç”±Vaswaniç­‰äººåœ¨2017å¹´æå‡º",
            "BERTæ˜¯åŒå‘ç¼–ç å™¨è¡¨ç¤ºæ¨¡å‹æ“…é•¿ç†è§£ä»»åŠ¡å¦‚åˆ†ç±»é—®ç­”ç­‰",
            "GPTæ˜¯ç”Ÿæˆå¼é¢„è®­ç»ƒæ¨¡å‹é‡‡ç”¨è‡ªå›å½’æ–¹å¼ç”Ÿæˆæ–‡æœ¬",
            "å¾®è°ƒFine-tuningæ˜¯åœ¨é¢„è®­ç»ƒæ¨¡å‹åŸºç¡€ä¸Šä½¿ç”¨ç‰¹å®šä»»åŠ¡æ•°æ®è¿›è¡Œè¿›ä¸€æ­¥è®­ç»ƒçš„è¿‡ç¨‹",
            "å‘é‡æ•°æ®åº“ç”¨äºå­˜å‚¨å’Œæ£€ç´¢é«˜ç»´å‘é‡å¸¸ç”¨äºç›¸ä¼¼åº¦æœç´¢",
            "æç¤ºå·¥ç¨‹Prompt Engineeringæ˜¯è®¾è®¡æœ‰æ•ˆè¾“å…¥æç¤ºæ¥å¼•å¯¼æ¨¡å‹äº§ç”ŸæœŸæœ›è¾“å‡ºçš„æŠ€æœ¯",
            "é‡åŒ–æŠ€æœ¯å¯ä»¥å°†æ¨¡å‹æƒé‡ä»32ä½æµ®ç‚¹æ•°å‹ç¼©åˆ°8ä½æˆ–4ä½æ•´æ•°æ˜¾è‘—å‡å°‘å†…å­˜ä½¿ç”¨",
            "æ¨ç†ä¼˜åŒ–åŒ…æ‹¬æ¨¡å‹é‡åŒ–å‰ªæçŸ¥è¯†è’¸é¦ç­‰æŠ€æœ¯ç”¨äºæå‡æ¨¡å‹éƒ¨ç½²æ•ˆç‡"
        ]
        self.add_documents(default_docs)
    
    def add_documents(self, docs):
        """æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
        # é¢„å¤„ç†æ–‡æ¡£
        processed_docs = [self.preprocess_text(doc) for doc in docs]
        
        self.documents.extend(docs)  # ä¿å­˜åŸå§‹æ–‡æ¡£ç”¨äºæ˜¾ç¤º
        
        # é‡æ–°è®­ç»ƒå‘é‡åŒ–å™¨
        all_processed = [self.preprocess_text(doc) for doc in self.documents]
        self.doc_vectors = self.vectorizer.fit_transform(all_processed)
        self.vectorizer_fitted = True
    
    def retrieve_documents(self, query, top_k=2):
        """æ£€ç´¢æœ€ç›¸å…³çš„æ–‡æ¡£"""
        if not self.documents or not self.vectorizer_fitted:
            return []
        
        # é¢„å¤„ç†æŸ¥è¯¢
        processed_query = self.preprocess_text(query)
        
        # å‘é‡åŒ–æŸ¥è¯¢
        query_vector = self.vectorizer.transform([processed_query])
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = cosine_similarity(query_vector, self.doc_vectors)[0]
        
        # é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œç¡®ä¿èƒ½æ£€ç´¢åˆ°æ–‡æ¡£
        min_similarity = 0.01  # å¾ˆä½çš„é˜ˆå€¼
        
        # è·å–top_kæœ€ç›¸ä¼¼çš„æ–‡æ¡£
        top_indices = np.argsort(similarities)[-top_k:][::-1]
        
        retrieved_docs = []
        for idx in top_indices:
            if similarities[idx] > min_similarity:
                retrieved_docs.append({
                    'content': self.documents[idx],
                    'similarity': similarities[idx]
                })
        
        # å¦‚æœæ²¡æœ‰æ£€ç´¢åˆ°ï¼Œè¿”å›ç›¸ä¼¼åº¦æœ€é«˜çš„æ–‡æ¡£
        if not retrieved_docs and len(similarities) > 0:
            best_idx = np.argmax(similarities)
            retrieved_docs.append({
                'content': self.documents[best_idx],
                'similarity': similarities[best_idx]
            })
        
        return retrieved_docs
    
    def generate_answer(self, query, retrieved_docs):
        """åŸºäºæ£€ç´¢åˆ°çš„æ–‡æ¡£ç”Ÿæˆç­”æ¡ˆ"""
        if not retrieved_docs:
            return "æŠ±æ­‰ï¼Œæˆ‘åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚è¯·å°è¯•æ·»åŠ ç›¸å…³æ–‡æ¡£æˆ–æ¢ä¸ªé—®é¢˜ã€‚"
        
        # ç®€å•çš„è§„åˆ™åŸºç¡€ç­”æ¡ˆç”Ÿæˆ
        best_doc = retrieved_docs[0]['content']
        
        # æ ¹æ®é—®é¢˜ç±»å‹ç”Ÿæˆä¸åŒé£æ ¼çš„å›ç­”
        if any(word in query for word in ["ä»€ä¹ˆæ˜¯", "æ˜¯ä»€ä¹ˆ", "å®šä¹‰"]):
            answer = f"æ ¹æ®çŸ¥è¯†åº“èµ„æ–™ï¼š{best_doc}"
        elif any(word in query for word in ["å¦‚ä½•", "æ€ä¹ˆ", "æ–¹æ³•"]):
            answer = f"å…³äºæ‚¨çš„é—®é¢˜ï¼Œç›¸å…³æ–¹æ³•å’Œä¿¡æ¯ï¼š{best_doc}"
        elif any(word in query for word in ["ä¸ºä»€ä¹ˆ", "åŸå› ", "why"]):
            answer = f"æ ¹æ®ç›¸å…³èµ„æ–™åˆ†æï¼š{best_doc}"
        else:
            answer = f"æ ¹æ®çŸ¥è¯†åº“ä¿¡æ¯ï¼š{best_doc}"
        
        # å¦‚æœæœ‰å¤šä¸ªç›¸å…³æ–‡æ¡£ï¼Œæ·»åŠ è¡¥å……ä¿¡æ¯
        if len(retrieved_docs) > 1:
            answer += f"\n\nğŸ“‹ è¡¥å……ä¿¡æ¯ï¼š{retrieved_docs[1]['content']}"
        
        return answer

# åˆå§‹åŒ–RAGç³»ç»Ÿ
rag_system = SimpleRAG()

def add_document_interface(doc_text):
    """æ·»åŠ æ–‡æ¡£çš„æ¥å£"""
    if doc_text.strip():
        # æŒ‰å¥å­åˆ†å‰²æ–‡æ¡£
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', doc_text)
        sentences = [s.strip() for s in sentences if s.strip() and len(s) > 5]
        
        if sentences:
            rag_system.add_documents(sentences)
            return f"âœ… å·²æ·»åŠ  {len(sentences)} ä¸ªæ–‡æ¡£ç‰‡æ®µåˆ°çŸ¥è¯†åº“"
        else:
            return "âŒ æœªæ£€æµ‹åˆ°æœ‰æ•ˆçš„æ–‡æ¡£å†…å®¹"
    return "âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ–‡æ¡£å†…å®¹"

def rag_chat(query, history):
    """RAGé—®ç­”ä¸»å‡½æ•°"""
    if not query.strip():
        return history, history
    
    try:
        # æ£€ç´¢ç›¸å…³æ–‡æ¡£
        retrieved_docs = rag_system.retrieve_documents(query, top_k=2)
        
        # ç”Ÿæˆç­”æ¡ˆ
        answer = rag_system.generate_answer(query, retrieved_docs)
        
        # æ·»åŠ æ£€ç´¢è¯¦æƒ…
        if retrieved_docs:
            retrieval_info = f"\n\nğŸ” **æ£€ç´¢è¯¦æƒ…ï¼š**\n"
            for i, doc in enumerate(retrieved_docs, 1):
                retrieval_info += f"{i}. ç›¸ä¼¼åº¦: {doc['similarity']:.3f} | å†…å®¹: {doc['content'][:80]}...\n"
            answer += retrieval_info
        
        # æ›´æ–°å¯¹è¯å†å²
        history.append([query, answer])
        
    except Exception as e:
        error_msg = f"âŒ å¤„ç†å‡ºé”™ï¼š{str(e)}"
        history.append([query, error_msg])
    
    return history, history

def clear_knowledge_base():
    """é‡ç½®çŸ¥è¯†åº“"""
    global rag_system
    rag_system = SimpleRAG()
    return "âœ… çŸ¥è¯†åº“å·²é‡ç½®ä¸ºé»˜è®¤å†…å®¹"

def show_knowledge_base():
    """æ˜¾ç¤ºå½“å‰çŸ¥è¯†åº“"""
    if rag_system.documents:
        docs_text = "\n".join([f"{i+1}. {doc}" for i, doc in enumerate(rag_system.documents)])
        return f"ğŸ“š å½“å‰çŸ¥è¯†åº“åŒ…å« {len(rag_system.documents)} ä¸ªæ–‡æ¡£ï¼š\n\n{docs_text}"
    return "ğŸ“š çŸ¥è¯†åº“ä¸ºç©º"

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(
    title="ğŸ¤– RAGé—®ç­”ç³»ç»Ÿæ¼”ç¤º",
    theme=gr.themes.Soft(),
    css=".gradio-container {max-width: 1200px; margin: auto;}"
) as demo:
    
    gr.Markdown("""
    # ğŸ¤– RAGé—®ç­”ç³»ç»Ÿæ¼”ç¤º
    
    **æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯æ¼”ç¤º** - é€‚åˆå¤§è¯­è¨€æ¨¡å‹å²—ä½é¢è¯•å±•ç¤º
    
    âœ¨ **æ ¸å¿ƒåŠŸèƒ½**ï¼šæ™ºèƒ½æ£€ç´¢ + ä¸Šä¸‹æ–‡ç”Ÿæˆ + çŸ¥è¯†åº“ç®¡ç†
    """)
    
    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ“š çŸ¥è¯†åº“ç®¡ç†")
            
            doc_input = gr.Textbox(
                label="ğŸ“ æ·»åŠ æ–‡æ¡£",
                placeholder="è¾“å…¥æŠ€æœ¯æ–‡æ¡£ã€è®ºæ–‡æ‘˜è¦æˆ–çŸ¥è¯†å†…å®¹...\nä¾‹å¦‚ï¼šæ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„å­é¢†åŸŸï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œæ¨¡æ‹Ÿäººè„‘å¤„ç†ä¿¡æ¯ã€‚",
                lines=6
            )
            
            with gr.Row():
                add_btn = gr.Button("â• æ·»åŠ åˆ°çŸ¥è¯†åº“", variant="primary", size="sm")
                show_btn = gr.Button("ğŸ‘ï¸ æŸ¥çœ‹çŸ¥è¯†åº“", variant="secondary", size="sm")
                reset_btn = gr.Button("ğŸ”„ é‡ç½®", variant="secondary", size="sm")
            
            status_output = gr.Textbox(label="ğŸ“Š æ“ä½œçŠ¶æ€", interactive=False, lines=2)
            
            kb_display = gr.Textbox(
                label="ğŸ“š çŸ¥è¯†åº“å†…å®¹",
                lines=8,
                interactive=False,
                visible=False
            )
        
        with gr.Column(scale=2):
            gr.Markdown("### ğŸ’¬ æ™ºèƒ½é—®ç­”")
            
            chatbot = gr.Chatbot(
                label="ğŸ¤– RAGå¯¹è¯åŠ©æ‰‹",
                height=450,
                show_label=True,
                avatar_images=("ğŸ‘¤", "ğŸ¤–")
            )
            
            with gr.Row():
                query_input = gr.Textbox(
                    label="ğŸ’­ è¾“å…¥é—®é¢˜",
                    placeholder="è¯•è¯•é—®ï¼šä»€ä¹ˆæ˜¯RAGæŠ€æœ¯ï¼Ÿ",
                    scale=4,
                    lines=1
                )
                send_btn = gr.Button("ğŸš€ å‘é€", variant="primary", scale=1)
            
            clear_chat_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯å†å²", variant="secondary", size="sm")
    
    # ç¤ºä¾‹é—®é¢˜åŒºåŸŸ
    gr.Markdown("""
    ### ğŸ’¡ ç¤ºä¾‹é—®é¢˜ï¼š
    `ä»€ä¹ˆæ˜¯å¤§è¯­è¨€æ¨¡å‹ï¼Ÿ` | `RAGæŠ€æœ¯çš„åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ` | `å¦‚ä½•è¿›è¡Œæ¨¡å‹å¾®è°ƒï¼Ÿ` | `Transformeræœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ`
    """)
    
    # æŠ€æœ¯è¯´æ˜
    with gr.Accordion("ğŸ”§ æŠ€æœ¯å®ç°è¯´æ˜", open=False):
        gr.Markdown("""
        ### ğŸ“‹ æŠ€æœ¯æ ˆ
        - **æ–‡æœ¬å‘é‡åŒ–**ï¼šTF-IDF + N-gramç‰¹å¾
        - **ç›¸ä¼¼åº¦è®¡ç®—**ï¼šCosineç›¸ä¼¼åº¦
        - **æ£€ç´¢ç­–ç•¥**ï¼šTop-Kæœ€ç›¸å…³æ–‡æ¡£æ£€ç´¢
        - **ç”Ÿæˆç­–ç•¥**ï¼šåŸºäºè§„åˆ™çš„ä¸Šä¸‹æ–‡æ•´åˆ
        - **ç•Œé¢æ¡†æ¶**ï¼šGradio
        
        ### ğŸ¯ RAGæµç¨‹
        1. **æ–‡æ¡£é¢„å¤„ç†**ï¼šæ–‡æœ¬æ¸…ç†ã€åˆ†å¥
        2. **å‘é‡åŒ–å­˜å‚¨**ï¼šTF-IDFç‰¹å¾æå–
        3. **æŸ¥è¯¢æ£€ç´¢**ï¼šè®¡ç®—æŸ¥è¯¢ä¸æ–‡æ¡£ç›¸ä¼¼åº¦
        4. **ç­”æ¡ˆç”Ÿæˆ**ï¼šåŸºäºæ£€ç´¢ç»“æœæ„å»ºå›ç­”
        5. **ç»“æœå±•ç¤º**ï¼šæ˜¾ç¤ºç­”æ¡ˆå’Œæ£€ç´¢è¿‡ç¨‹
        """)
    
    # äº‹ä»¶ç»‘å®š
    add_btn.click(
        fn=add_document_interface,
        inputs=[doc_input],
        outputs=[status_output]
    ).then(
        fn=lambda: "",
        outputs=[doc_input]
    )
    
    show_btn.click(
        fn=show_knowledge_base,
        outputs=[kb_display]
    ).then(
        fn=lambda: gr.update(visible=True),
        outputs=[kb_display]
    )
    
    reset_btn.click(
        fn=clear_knowledge_base,
        outputs=[status_output]
    ).then(
        fn=lambda: gr.update(visible=False),
        outputs=[kb_display]
    )
    
    send_btn.click(
        fn=rag_chat,
        inputs=[query_input, chatbot],
        outputs=[chatbot, chatbot]
    ).then(
        fn=lambda: "",
        outputs=[query_input]
    )
    
    query_input.submit(
        fn=rag_chat,
        inputs=[query_input, chatbot],
        outputs=[chatbot, chatbot]
    ).then(
        fn=lambda: "",
        outputs=[query_input]
    )
    
    clear_chat_btn.click(
        fn=lambda: [],
        outputs=[chatbot]
    )

# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    demo.launch()