import gradio as gr
import torch
from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM
from sentence_transformers import SentenceTransformer
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import re
import os

class SimpleRAG:
    def __init__(self):
        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ï¼ˆç”¨äºæ–‡æ¡£æ£€ç´¢ï¼‰
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # åˆå§‹åŒ–ç”Ÿæˆæ¨¡å‹ï¼ˆè½»é‡çº§ï¼‰
        self.tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-medium')
        self.generator = AutoModelForCausalLM.from_pretrained('microsoft/DialoGPT-medium')
        
        # çŸ¥è¯†åº“
        self.documents = []
        self.doc_embeddings = None
        
        # é»˜è®¤çŸ¥è¯†åº“å†…å®¹
        self.load_default_knowledge()
    
    def load_default_knowledge(self):
        """åŠ è½½é»˜è®¤çŸ¥è¯†åº“"""
        default_docs = [
            "å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ˜¯åŸºäºTransformeræ¶æ„çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œèƒ½å¤Ÿç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚",
            "RAGï¼ˆRetrieval-Augmented Generationï¼‰æ˜¯ä¸€ç§ç»“åˆæ£€ç´¢å’Œç”Ÿæˆçš„æ–¹æ³•ï¼Œé€šè¿‡æ£€ç´¢ç›¸å…³æ–‡æ¡£æ¥å¢å¼ºç”Ÿæˆè´¨é‡ã€‚",
            "Transformeræ˜¯ä¸€ç§åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„ç¥ç»ç½‘ç»œæ¶æ„ï¼Œç”±Vaswaniç­‰äººåœ¨2017å¹´æå‡ºã€‚",
            "BERTæ˜¯åŒå‘ç¼–ç å™¨è¡¨ç¤ºæ¨¡å‹ï¼Œæ“…é•¿ç†è§£ä»»åŠ¡å¦‚åˆ†ç±»ã€é—®ç­”ç­‰ã€‚",
            "GPTæ˜¯ç”Ÿæˆå¼é¢„è®­ç»ƒæ¨¡å‹ï¼Œé‡‡ç”¨è‡ªå›å½’æ–¹å¼ç”Ÿæˆæ–‡æœ¬ã€‚",
            "å¾®è°ƒï¼ˆFine-tuningï¼‰æ˜¯åœ¨é¢„è®­ç»ƒæ¨¡å‹åŸºç¡€ä¸Šï¼Œä½¿ç”¨ç‰¹å®šä»»åŠ¡æ•°æ®è¿›è¡Œè¿›ä¸€æ­¥è®­ç»ƒçš„è¿‡ç¨‹ã€‚",
            "å‘é‡æ•°æ®åº“ç”¨äºå­˜å‚¨å’Œæ£€ç´¢é«˜ç»´å‘é‡ï¼Œå¸¸ç”¨äºç›¸ä¼¼åº¦æœç´¢ã€‚",
            "æç¤ºå·¥ç¨‹ï¼ˆPrompt Engineeringï¼‰æ˜¯è®¾è®¡æœ‰æ•ˆè¾“å…¥æç¤ºæ¥å¼•å¯¼æ¨¡å‹äº§ç”ŸæœŸæœ›è¾“å‡ºçš„æŠ€æœ¯ã€‚",
            "é‡åŒ–æŠ€æœ¯å¯ä»¥å°†æ¨¡å‹æƒé‡ä»32ä½æµ®ç‚¹æ•°å‹ç¼©åˆ°8ä½æˆ–4ä½æ•´æ•°ï¼Œæ˜¾è‘—å‡å°‘å†…å­˜ä½¿ç”¨ã€‚",
            "æ¨ç†ä¼˜åŒ–åŒ…æ‹¬æ¨¡å‹é‡åŒ–ã€å‰ªæã€çŸ¥è¯†è’¸é¦ç­‰æŠ€æœ¯ï¼Œç”¨äºæå‡æ¨¡å‹éƒ¨ç½²æ•ˆç‡ã€‚"
        ]
        self.add_documents(default_docs)
    
    def add_documents(self, docs):
        """æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
        self.documents.extend(docs)
        # è®¡ç®—æ–‡æ¡£åµŒå…¥
        embeddings = self.embedding_model.encode(docs)
        
        if self.doc_embeddings is None:
            self.doc_embeddings = embeddings
        else:
            self.doc_embeddings = np.vstack([self.doc_embeddings, embeddings])
    
    def retrieve_documents(self, query, top_k=2):
        """æ£€ç´¢æœ€ç›¸å…³çš„æ–‡æ¡£"""
        if not self.documents:
            return []
        
        # è®¡ç®—æŸ¥è¯¢åµŒå…¥
        query_embedding = self.embedding_model.encode([query])
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = cosine_similarity(query_embedding, self.doc_embeddings)[0]
        
        # è·å–top_kæœ€ç›¸ä¼¼çš„æ–‡æ¡£
        top_indices = np.argsort(similarities)[-top_k:][::-1]
        
        retrieved_docs = []
        for idx in top_indices:
            retrieved_docs.append({
                'content': self.documents[idx],
                'similarity': similarities[idx]
            })
        
        return retrieved_docs
    
    def generate_answer(self, query, retrieved_docs):
        """åŸºäºæ£€ç´¢åˆ°çš„æ–‡æ¡£ç”Ÿæˆç­”æ¡ˆ"""
        # æ„å»ºä¸Šä¸‹æ–‡
        context = "\n".join([doc['content'] for doc in retrieved_docs])
        
        # æ„å»ºæç¤º
        prompt = f"""åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ï¼š

ä¸Šä¸‹æ–‡ï¼š
{context}

é—®é¢˜ï¼š{query}

ç­”æ¡ˆï¼š"""
        
        # ç”±äºDialoGPTä¸»è¦ç”¨äºå¯¹è¯ï¼Œè¿™é‡Œæˆ‘ä»¬ç®€åŒ–å¤„ç†
        # å®é™…é¡¹ç›®ä¸­å»ºè®®ä½¿ç”¨ä¸“é—¨çš„QAæ¨¡å‹
        if retrieved_docs:
            # åŸºäºæ£€ç´¢åˆ°çš„æ–‡æ¡£æ„å»ºç®€å•å›ç­”
            answer = self.simple_answer_generation(query, retrieved_docs)
        else:
            answer = "æŠ±æ­‰ï¼Œæˆ‘åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
        
        return answer
    
    def simple_answer_generation(self, query, retrieved_docs):
        """ç®€å•çš„ç­”æ¡ˆç”Ÿæˆé€»è¾‘"""
        # æ‰¾åˆ°æœ€ç›¸å…³çš„æ–‡æ¡£
        best_doc = retrieved_docs[0]['content']
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…å’Œç­”æ¡ˆæ„å»º
        if "ä»€ä¹ˆæ˜¯" in query or "æ˜¯ä»€ä¹ˆ" in query:
            return f"æ ¹æ®æˆ‘çš„çŸ¥è¯†åº“ï¼š{best_doc}"
        elif "å¦‚ä½•" in query or "æ€ä¹ˆ" in query:
            related_info = [doc['content'] for doc in retrieved_docs]
            return f"å…³äºæ‚¨çš„é—®é¢˜ï¼Œç›¸å…³ä¿¡æ¯å¦‚ä¸‹ï¼š\n" + "\n".join(related_info)
        else:
            return f"æ ¹æ®ç›¸å…³èµ„æ–™ï¼š{best_doc}\n\nè¡¥å……ä¿¡æ¯ï¼š{retrieved_docs[1]['content'] if len(retrieved_docs) > 1 else ''}"

# åˆå§‹åŒ–RAGç³»ç»Ÿ
rag_system = SimpleRAG()

def add_document_interface(doc_text):
    """æ·»åŠ æ–‡æ¡£çš„æ¥å£"""
    if doc_text.strip():
        # æŒ‰å¥å­åˆ†å‰²æ–‡æ¡£
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', doc_text)
        sentences = [s.strip() for s in sentences if s.strip()]
        rag_system.add_documents(sentences)
        return f"å·²æ·»åŠ  {len(sentences)} ä¸ªæ–‡æ¡£ç‰‡æ®µåˆ°çŸ¥è¯†åº“"
    return "è¯·è¾“å…¥æœ‰æ•ˆçš„æ–‡æ¡£å†…å®¹"

def rag_chat(query, history):
    """RAGé—®ç­”ä¸»å‡½æ•°"""
    if not query.strip():
        return history, history
    
    # æ£€ç´¢ç›¸å…³æ–‡æ¡£
    retrieved_docs = rag_system.retrieve_documents(query, top_k=2)
    
    # ç”Ÿæˆç­”æ¡ˆ
    answer = rag_system.generate_answer(query, retrieved_docs)
    
    # æ·»åŠ æ£€ç´¢ä¿¡æ¯
    retrieval_info = ""
    if retrieved_docs:
        retrieval_info = f"\n\nğŸ“š **æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£ï¼š**\n"
        for i, doc in enumerate(retrieved_docs, 1):
            retrieval_info += f"{i}. {doc['content'][:100]}... (ç›¸ä¼¼åº¦: {doc['similarity']:.3f})\n"
    
    full_answer = answer + retrieval_info
    
    # æ›´æ–°å¯¹è¯å†å²
    history.append([query, full_answer])
    
    return history, history

def clear_knowledge_base():
    """æ¸…ç©ºçŸ¥è¯†åº“"""
    global rag_system
    rag_system = SimpleRAG()  # é‡æ–°åˆå§‹åŒ–ï¼Œä¼šåŠ è½½é»˜è®¤çŸ¥è¯†
    return "çŸ¥è¯†åº“å·²é‡ç½®ä¸ºé»˜è®¤å†…å®¹"

def show_knowledge_base():
    """æ˜¾ç¤ºå½“å‰çŸ¥è¯†åº“å†…å®¹"""
    if rag_system.documents:
        docs_text = "\n".join([f"{i+1}. {doc}" for i, doc in enumerate(rag_system.documents)])
        return f"å½“å‰çŸ¥è¯†åº“åŒ…å« {len(rag_system.documents)} ä¸ªæ–‡æ¡£ï¼š\n\n{docs_text}"
    return "çŸ¥è¯†åº“ä¸ºç©º"

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(title="ğŸ¤– RAGé—®ç­”ç³»ç»Ÿæ¼”ç¤º", theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ¤– RAGé—®ç­”ç³»ç»Ÿæ¼”ç¤º
    
    è¿™æ˜¯ä¸€ä¸ªåŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰çš„é—®ç­”ç³»ç»ŸåŸå‹ã€‚ç³»ç»Ÿä¼šä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼Œç„¶åç”Ÿæˆç­”æ¡ˆã€‚
    
    ## åŠŸèƒ½ç‰¹ç‚¹ï¼š
    - ğŸ“– çŸ¥è¯†åº“ç®¡ç†ï¼šæ·»åŠ è‡ªå®šä¹‰æ–‡æ¡£
    - ğŸ” æ™ºèƒ½æ£€ç´¢ï¼šåŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢ç›¸å…³æ–‡æ¡£  
    - ğŸ’¬ é—®ç­”ç”Ÿæˆï¼šç»“åˆæ£€ç´¢ç»“æœç”Ÿæˆç­”æ¡ˆ
    - ğŸ“Š é€æ˜åº¦ï¼šæ˜¾ç¤ºæ£€ç´¢è¿‡ç¨‹å’Œç›¸ä¼¼åº¦åˆ†æ•°
    """)
    
    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ“š çŸ¥è¯†åº“ç®¡ç†")
            
            doc_input = gr.Textbox(
                label="æ·»åŠ æ–‡æ¡£",
                placeholder="è¾“å…¥è¦æ·»åŠ åˆ°çŸ¥è¯†åº“çš„æ–‡æ¡£å†…å®¹...",
                lines=5
            )
            
            with gr.Row():
                add_btn = gr.Button("â• æ·»åŠ æ–‡æ¡£", variant="primary")
                clear_btn = gr.Button("ğŸ—‘ï¸ é‡ç½®çŸ¥è¯†åº“", variant="secondary")
                show_btn = gr.Button("ğŸ‘ï¸ æŸ¥çœ‹çŸ¥è¯†åº“", variant="secondary")
            
            doc_status = gr.Textbox(label="çŠ¶æ€", interactive=False)
            
            knowledge_display = gr.Textbox(
                label="çŸ¥è¯†åº“å†…å®¹",
                lines=10,
                interactive=False,
                visible=False
            )
        
        with gr.Column(scale=2):
            gr.Markdown("### ğŸ’¬ RAGé—®ç­”")
            
            chatbot = gr.Chatbot(
                label="å¯¹è¯å†å²",
                height=400,
                show_label=True
            )
            
            msg = gr.Textbox(
                label="è¾“å…¥é—®é¢˜",
                placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œæ¯”å¦‚ï¼šä»€ä¹ˆæ˜¯RAGï¼Ÿ",
                lines=2
            )
            
            with gr.Row():
                submit_btn = gr.Button("ğŸš€ æé—®", variant="primary")
                clear_chat_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", variant="secondary")
    
    # ç¤ºä¾‹é—®é¢˜
    gr.Markdown("""
    ### ğŸ’¡ ç¤ºä¾‹é—®é¢˜ï¼š
    - ä»€ä¹ˆæ˜¯å¤§è¯­è¨€æ¨¡å‹ï¼Ÿ
    - RAGæ˜¯ä»€ä¹ˆæŠ€æœ¯ï¼Ÿ
    - å¦‚ä½•è¿›è¡Œæ¨¡å‹å¾®è°ƒï¼Ÿ
    - Transformeræ¶æ„æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ
    """)
    
    # äº‹ä»¶ç»‘å®š
    add_btn.click(
        add_document_interface,
        inputs=[doc_input],
        outputs=[doc_status]
    ).then(
        lambda: "",
        outputs=[doc_input]
    )
    
    clear_btn.click(
        clear_knowledge_base,
        outputs=[doc_status]
    )
    
    show_btn.click(
        show_knowledge_base,
        outputs=[knowledge_display]
    ).then(
        lambda: gr.update(visible=True),
        outputs=[knowledge_display]
    )
    
    submit_btn.click(
        rag_chat,
        inputs=[msg, chatbot],
        outputs=[chatbot, chatbot]
    ).then(
        lambda: "",
        outputs=[msg]
    )
    
    msg.submit(
        rag_chat,
        inputs=[msg, chatbot],
        outputs=[chatbot, chatbot]
    ).then(
        lambda: "",
        outputs=[msg]
    )
    
    clear_chat_btn.click(
        lambda: [],
        outputs=[chatbot]
    )

if __name__ == "__main__":
    demo.launch()