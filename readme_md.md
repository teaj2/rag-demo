# 🤖 RAG问答系统演示

基于检索增强生成（RAG）技术的问答系统原型，展示了现代大语言模型应用的核心技术栈。

## 🌟 项目特点

- **智能检索**：基于语义相似度的文档检索
- **增强生成**：结合检索结果的答案生成
- **可视化界面**：直观的Web界面展示检索过程
- **知识库管理**：支持动态添加和管理文档
- **轻量化部署**：适合快速原型验证

## 🛠️ 技术栈

- **前端**：Gradio（快速Web界面构建）
- **嵌入模型**：Sentence-Transformers（语义向量化）
- **生成模型**：Microsoft DialoGPT（对话生成）
- **相似度计算**：Scikit-learn Cosine Similarity
- **部署平台**：Hugging Face Spaces

## 🚀 快速开始

### 本地运行
```bash
# 1. 克隆项目
git clone <your-repo>
cd rag-demo

# 2. 安装依赖
pip install -r requirements.txt

# 3. 运行应用
python app.py
```

### Hugging Face Spaces部署
1. 在 [Hugging Face Spaces](https://huggingface.co/spaces) 创建新的Space
2. 选择 Gradio SDK
3. 上传 `app.py` 和 `requirements.txt`
4. 等待自动部署完成

## 📋 核心功能

### 1. 知识库管理
- 添加自定义文档内容
- 自动文档分割和向量化
- 查看当前知识库状态

### 2. 智能问答
- 基于语义相似度检索相关文档
- 结合上下文生成回答
- 显示检索过程和相似度分数

### 3. 对话历史
- 保持对话上下文
- 支持多轮问答
- 清空对话记录

## 🎯 使用场景

- **技术面试**：展示RAG技术理解
- **原型验证**：快速验证RAG想法
- **学习演示**：理解检索增强生成流程
- **项目基础**：作为更复杂系统的起点

## 📈 可扩展方向

### 短期优化
- 集成更强的生成模型（如ChatGLM）
- 添加多种文档格式支持（PDF、Word等）
- 优化检索算法（如混合检索）

### 长期规划
- 接入向量数据库（Pinecone、Chroma）
- 添加对话记忆机制
- 实现模型微调功能
- 支持多模态输入

## 🔧 技术细节

### RAG流程
1. **文档预处理**：分割、清洗文本
2. **向量化**：使用Sentence-Transformers编码
3. **检索**：基于cosine相似度找到最相关文档
4. **生成**：结合检索结果生成答案
5. **后处理**：格式化输出结果

### 模型选择
- **嵌入模型**：all-MiniLM-L6-v2（轻量、效果好）
- **生成模型**：DialoGPT-medium（平衡性能和速度）

## 📝 面试要点

### 技术深度
- **RAG原理**：检索-增强-生成三个核心步骤
- **向量检索**：语义相似度计算方法
- **模型架构**：Transformer、BERT、GPT差异

### 工程能力
- **系统设计**：模块化代码结构
- **用户体验**：直观的界面设计
- **部署能力**：云端快速部署

### 扩展思路
- **性能优化**：模型量化、缓存机制
- **功能增强**：多轮对话、个性化推荐
- **工程化**：监控、日志、A/B测试

## ⚠️ 注意事项

- 当前使用轻量级模型，生成质量有限
- 知识库存储在内存中，重启后丢失
- 适合演示和学习，生产环境需要进一步优化

## 🤝 贡献

欢迎提交Issue和Pull Request来改进这个项目！

---

**项目作者**：电子信息研究生  
**用途**：大语言模型岗位实习申请演示项目